{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LZW\n",
    "\n",
    "This notebook provides a visually aided demonstration of the compression ratio of text files compressed using the [Lempel-Ziv-Welch](https://en.wikipedia.org/wiki/Lempel%E2%80%93Ziv%E2%80%93Welch) coding technique. The [lzw](https://github.com/pytholic97/LZW-Text-File-Compression) python package is used to compress the files. \n",
    "\n",
    "The text files used for compression have been generated by sampling characters in the ascii range 0 through 127 from 3 different probability distributions:\n",
    "\n",
    "* Poisson\n",
    "* Gaussian\n",
    "* Uniform\n",
    "\n",
    "The statistical parameters of the distributions - such as mean and std deviation for Gaussian pdf - have been suitably varied to obtain a general idea of how the LZW technique depends not only on the distributions themselves but also their individual statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/coesip/7069/lzw/bin/python3\r\n"
     ]
    }
   ],
   "source": [
    "! which python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.externals import joblib\n",
    "import lzw\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for saving results of compression and decompression\n",
    "\n",
    "res_dict = dict()\n",
    "res_dict['pdf'], res_dict['size'], res_dict['comp_size'] = [], [], []\n",
    "res_dict['comp_time'], res_dict['decomp_time'] = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2000000.txt',\n",
       " '1000000.txt',\n",
       " '4000000.txt',\n",
       " '10000000.txt',\n",
       " '8000000.txt',\n",
       " '500000.txt',\n",
       " '6000000.txt']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdfff = 'Poisson'\n",
    "os.chdir('/home/coesip/7069/files/' + pdfff + '1/original')\n",
    "to_comp = [_ for _ in os.listdir() if int(_.split('.')[0]) > 0 and int(_.split('.')[0]) <= 10000000]\n",
    "#to_comp = ['10000000.txt','36000000.txt','40000000.txt']\n",
    "to_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000000.txt decompressed. Time taken: 0:00:10.968440\n"
     ]
    }
   ],
   "source": [
    "pdff = 'Poisson'\n",
    "os.chdir('/home/coesip/7069/files/' + pdff + '1/original')\n",
    "\n",
    "comp_path = '/home/coesip/7069/files/' + pdff + '1/compressed/'\n",
    "decomp_path = '/home/coesip/7069/files/' + pdff + '1/decompressed/'\n",
    "file_path = '/home/coesip/7069/files/' + pdff + '1/original/'\n",
    "\n",
    "from lzw.Compress import compress as cmp\n",
    "from lzw.Decompress import decompress as dec\n",
    "\n",
    "for file in to_comp:\n",
    "    res_dict['pdf'].append(pdff)\n",
    "    #res_dict['size'].append(file.split('.')[0])\n",
    "    res_dict['size'].append(os.path.getsize(file_path+file))\n",
    "    \n",
    "    clear_output()\n",
    "    print('Processing '+file)\n",
    "    c = cmp(file_path+file, comp_path, encoding='ascii_127', verbose=1, limit=50000000)\n",
    "    start_time = time.monotonic()\n",
    "    c.encode()\n",
    "    end_time = time.monotonic()\n",
    "    clear_output()\n",
    "    print(file + ' compressed. Time taken: '+ str(timedelta(seconds=end_time - start_time)))\n",
    "    \n",
    "    res_dict['comp_time'].append(end_time - start_time)\n",
    "    res_dict['comp_size'].append(os.path.getsize(comp_path+file.split('.')[0]+'_compressed.txt'))\n",
    "    \n",
    "    \n",
    "    d = dec(comp_path+file.split('.')[0]+'_compressed.txt', decomp_path, encoding='ascii_127', verbose=1, limit=50000000)\n",
    "    start_time = time.monotonic()\n",
    "    d.decode()\n",
    "    end_time = time.monotonic()\n",
    "    res_dict['decomp_time'].append(end_time - start_time)\n",
    "    clear_output()\n",
    "    print(file + ' decompressed. Time taken: '+str(timedelta(seconds=end_time - start_time)))\n",
    "\n",
    "    if abs(os.path.getsize(decomp_path+file.split('.')[0]+'_compressed_decompressed.txt')-os.path.getsize(file_path+file)) > 10:\n",
    "        print(\"error in file \" + file)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/coesip/7069/LZW-Compression/test_objects/test1/Poisson1/pois_all_le10MB.sav']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving results object\n",
    "#res_dict['size']    \n",
    "res_dict['size']\n",
    "joblib.dump(res_dict, '/home/coesip/7069/LZW-Compression/test_objects/test1/' + pdff + '1/pois_all_le10MB.sav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
